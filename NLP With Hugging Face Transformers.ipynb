{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Natural Language Processing with Hugging Face Transformers"
      ],
      "metadata": {
        "id": "QMe0GsCHo_ZL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CztodpmQM11q"
      },
      "source": [
        "**NLP (Natural Language Processing)** adalah cabang dari kecerdasan buatan (AI) yang berfokus pada interaksi antara komputer dan bahasa manusia. Tujuan utama NLP adalah untuk memungkinkan mesin memahami, menafsirkan, dan menghasilkan bahasa manusia dengan cara yang bermakna.\n",
        "\n",
        "**Contoh Aplikasi NLP:**\n",
        "\n",
        "Text Classification: Mengategorikan teks ke dalam kategori tertentu (misalnya, spam vs. non-spam).\n",
        "\n",
        "Sentiment Analysis: Menganalisis emosi atau opini dari teks (positif, netral, negatif).\n",
        "\n",
        "Text Generation: Menghasilkan teks berdasarkan input tertentu.\n",
        "\n",
        "Named Entity Recognition (NER): Mengidentifikasi entitas dalam teks, seperti nama orang, tempat, atau organisasi.\n",
        "\n",
        "Machine Translation: Menerjemahkan teks dari satu bahasa ke bahasa lain.\n",
        "\n",
        "Question Answering: Menjawab pertanyaan berdasarkan teks yang diberikan.\n",
        "\n",
        "Text Summarization: Merangkum teks panjang menjadi versi yang lebih ringkas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Instal Library\n"
      ],
      "metadata": {
        "id": "ZMNv3SGiqfTa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dtAhiTAMmYN",
        "outputId": "5a1c99e2-3038-4409-d48a-ebae2839af1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "fungsi tiap library :\n",
        "1.   Transformers: Menyediakan model NLP canggih dan pipeline abstraksi.\n",
        "2.   Torch: Menyediakan backend untuk komputasi tensor dan akselerasi GPU.\n",
        "3.    Pandas: Mengelola, memanipulasi, dan menyimpan data hasil analisis."
      ],
      "metadata": {
        "id": "-OMiUB5KuC7B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import library"
      ],
      "metadata": {
        "id": "xSsbJnpL0BqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "slEzK6M20DzX"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Contoh 1 - Sentiment analysis"
      ],
      "metadata": {
        "id": "xzG_X0HTsl3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analisis sentimen adalah teknik pemrosesan bahasa alami yang mengidentifikasi polaritas teks tertentu. Beberapa penggunaan praktis analisis sentimen yang paling umum adalah analisis tweet, ulasan produk, klasifikasi tiket dukungan, dan lainnya. Analisis sentimen memungkinkan pemrosesan cepat sejumlah besar data waktu nyata."
      ],
      "metadata": {
        "id": "VgeDs6jEuwlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Sentiment Analysis pipeline\n",
        "sentiment_analysis = pipeline(\"sentiment-analysis\", model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "# Example text\n",
        "result = sentiment_analysis(\"I love using Hugging Face Transformers!\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "sSt-JVGmu9Jq",
        "outputId": "add602bf-e6b9-46fc-ce6a-520625e31b5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'POSITIVE', 'score': 0.9971315860748291}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Contoh 2 - Topic Classification"
      ],
      "metadata": {
        "id": "Cw03HD9W0QsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Zero-shot Classification pipeline\n",
        "topic_classifier = pipeline(\"zero-shot-classification\",  model=\"facebook/bart-large-mnli\")\n",
        "\n",
        "# Example text and candidate labels\n",
        "text = \"Hugging Face Transformers are great for NLP tasks.\"\n",
        "candidate_labels = [\"technology\", \"health\", \"sports\"]\n",
        "\n",
        "# Classify text\n",
        "result = topic_classifier(text, candidate_labels)\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "RlLhIPXAzBgP",
        "outputId": "a3f8a80c-2e26-470c-d996-3838db9995dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sequence': 'Hugging Face Transformers are great for NLP tasks.', 'labels': ['technology', 'health', 'sports'], 'scores': [0.9802375435829163, 0.011585185304284096, 0.008177289739251137]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Contoh 3 - Text Generation"
      ],
      "metadata": {
        "id": "gAKriosw2T58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "# Load Text Generation pipeline\n",
        "text_generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "\n",
        "# Set logging level to ERROR to suppress warnings\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
        "\n",
        "# Example with truncation\n",
        "result = text_generator(\"One day, have a girl sit in garden,\", max_length=50, truncation=True)\n",
        "print(result[0][\"generated_text\"])"
      ],
      "metadata": {
        "id": "c8RVC9l02jD8",
        "outputId": "5302744d-076e-451c-fbb0-9ed0e242ff6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One day, have a girl sit in garden, read her book, read some funny books, walk by the lake in forest to eat food, and when the sun reaches the horizon. Then stand next to a beautiful young man, a boy, and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Contoh 4 - Named Entity Recognition (NER)"
      ],
      "metadata": {
        "id": "jODCk93-2jb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load NER pipeline\n",
        "ner = pipeline(\"ner\", grouped_entities=True)\n",
        "\n",
        "# Set logging level to ERROR to suppress warnings\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
        "\n",
        "# Example text\n",
        "result = ner(\"I Live in Indonesian\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "qW1IfPr34Kj6",
        "outputId": "694f1cba-d6ae-4216-8955-4d5ccec8867b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'entity_group': 'MISC', 'score': 0.99019414, 'word': 'Indonesian', 'start': 10, 'end': 20}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Contoh 5 - Question Answering"
      ],
      "metadata": {
        "id": "jeMekNbN4JoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set logging level to ERROR to suppress warnings\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
        "\n",
        "# Load Question Answering pipeline\n",
        "qa = pipeline(\"question-answering\")\n",
        "\n",
        "# Example question and context\n",
        "question = \"Dimana dia tinggal?\"\n",
        "context = \"dia tinggal di Indonesia\"\n",
        "result = qa(question=question, context=context)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "4soUYH2m58NF",
        "outputId": "3fe6d393-6a59-4278-ed77-de590ef24988",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'score': 0.3130703866481781, 'start': 0, 'end': 24, 'answer': 'dia tinggal di Indonesia'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Contoh 6 - Text Summarization"
      ],
      "metadata": {
        "id": "CPNr1Q8O65pc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Summarization pipeline\n",
        "summarizer = pipeline(\"summarization\")\n",
        "\n",
        "# Example text\n",
        "long_text = \"\"\"\n",
        "Konsep kehidupan setelah kematian dapat berbeda-beda dalam berbagai budaya, agama, dan filosofi. Dalam Islam, kehidupan setelah kematian diyakini sebagai bentuk eksistensi yang berlanjut setelah kematian fisik. Berikut beberapa tahapan kehidupan setelah kematian dalam Islam:\n",
        "Alam Barzakh: Alam kubur yang merupakan batas antara dunia dan akhirat. Di alam ini, ruh manusia menunggu penghakiman dan dihitung amal perbuatannya.\n",
        "Yaumul Ba'ats: Hari kebangkitan, ketika Allah membangkitkan semua orang mati dari kubur.\n",
        "Yaumul Mahsyar: Hari berkumpulnya semua makhluk, termasuk manusia, jin, dan hewan, untuk diadili.\n",
        "Yaumul Mizan: Hari penimbangan.\n",
        "Yaumul Hisab: Hari perhitungan, ketika setiap orang dimintai pertanggungjawaban atas perbuatannya.\n",
        "Yaumul Sirat: Hari melewati jembatan untuk mencapai surga.\n",
        "Surga atau Neraka: Nasib akhir setiap orang ditentukan, apakah akan masuk surga atau neraka.\n",
        "Dalam Islam, kehidupan setelah kematian berfungsi sebagai pengingat untuk menjalani kehidupan yang benar dan mempersiapkan kehidupan akhirat.\n",
        "\"\"\"\n",
        "result = summarizer(long_text, max_length=100, min_length=50, do_sample=False)\n",
        "print(result[0][\"summary_text\"])\n"
      ],
      "metadata": {
        "id": "FTK2iywb69ub",
        "outputId": "f6c76fe7-d581-495f-f09c-ac7c16dabe02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Konsep kehidupan setelah kematian dapat berbeda-beda dalam berbagai budaya, agama, dan filosofi . Di alam ini, ruh manusia menunggu penghakiman dan dihitung amal perbuatannya .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Contoh 7 - Text Translation"
      ],
      "metadata": {
        "id": "o0_xElHk8M2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Translation pipeline\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-id\")\n",
        "\n",
        "# Example text\n",
        "result = translator(\"I miss you\")\n",
        "print(result[0][\"translation_text\"])"
      ],
      "metadata": {
        "id": "uHOxo88S8Vao",
        "outputId": "26456c5a-002e-4657-f498-58a6664cdaca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aku merindukanmu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vbYVRh2bn4y"
      },
      "source": [
        "# Analisis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPnbUWgabrs8"
      },
      "source": [
        "1. Sentiment analysis : Ini untuk mengetahui apakah sebuah teks berisi perasaan positif, negatif, atau netral.\n",
        "\n",
        "2. Topic Classification : Ini untuk mengklasifikasikan teks ke dalam kategori tertentu, seperti teknologi atau olahraga. Model dapat menebak topik teks, bahkan tanpa pelatihan khusus.\n",
        "\n",
        "3. Text Generation : Tugas ini membuat teks baru berdasarkan input yang diberikan. Misalnya, memberikan kalimat awal dan membiarkan model untuk melanjutkannya.\n",
        "\n",
        "4. Named Entity Recognition (NER) : Ini untuk mengenali nama orang, tempat, atau hal penting lainnya dalam teks, seperti nama kota atau perusahaan.\n",
        "\n",
        "5. Question Answering : Ini untuk menjawab pertanyaan berdasarkan informasi yang diberikan dalam teks.\n",
        "\n",
        "6. Text Summarization : Tugas ini merangkum teks panjang menjadi lebih singkat tanpa kehilangan makna utamanya.\n",
        "\n",
        "7. Text Translation : Ini untuk menerjemahkan teks dari satu bahasa ke bahasa lain.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}